{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  IMT574 Problem Set 5: Na√Øve Bayes\n",
    "\n",
    "### Group :Yash Raichura, Ganapathy SL, Roshni Roy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "\n",
    "data=pd.read_csv(\"rotten-tomatoes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.timeout.com/film/reviews/87745/toy-...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.time.com/time/magazine/article/0,91...</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.newsweek.com/id/104199</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.variety.com/review/VE1117941294.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://onfilm.chicagoreader.com/movies/capsule...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Michael Booth</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.denverpost.com/movies/ci_5786068</td>\n",
       "      <td>Denver Post</td>\n",
       "      <td>As Lion King did before it, Toy Story revived ...</td>\n",
       "      <td>2007-05-03 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Geoff Andrew</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.timeout.com/film/reviews/79673/toy_...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>The film will probably be more fully appreciat...</td>\n",
       "      <td>2006-06-24 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Janet Maslin</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://movies.nytimes.com/movie/review?res=990...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Children will enjoy a new take on the irresist...</td>\n",
       "      <td>2003-05-20 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kenneth Turan</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.calendarlive.com/movies/reviews/cl-...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>Although its computer-generated imagery is imp...</td>\n",
       "      <td>2001-02-13 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Roger Ebert</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.rogerebert.com/reviews/toy-story-1995</td>\n",
       "      <td>Chicago Sun-Times</td>\n",
       "      <td>The result is a visionary roller-coaster ride ...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb  \\\n",
       "0         Derek Adams  fresh  114709   \n",
       "1     Richard Corliss  fresh  114709   \n",
       "2         David Ansen  fresh  114709   \n",
       "3       Leonard Klady  fresh  114709   \n",
       "4  Jonathan Rosenbaum  fresh  114709   \n",
       "5       Michael Booth  fresh  114709   \n",
       "6        Geoff Andrew  fresh  114709   \n",
       "7        Janet Maslin  fresh  114709   \n",
       "8       Kenneth Turan  fresh  114709   \n",
       "9         Roger Ebert  fresh  114709   \n",
       "\n",
       "                                                link        publication  \\\n",
       "0  http://www.timeout.com/film/reviews/87745/toy-...           Time Out   \n",
       "1  http://www.time.com/time/magazine/article/0,91...      TIME Magazine   \n",
       "2                  http://www.newsweek.com/id/104199           Newsweek   \n",
       "3  http://www.variety.com/review/VE1117941294.htm...            Variety   \n",
       "4  http://onfilm.chicagoreader.com/movies/capsule...     Chicago Reader   \n",
       "5        http://www.denverpost.com/movies/ci_5786068        Denver Post   \n",
       "6  http://www.timeout.com/film/reviews/79673/toy_...           Time Out   \n",
       "7  http://movies.nytimes.com/movie/review?res=990...     New York Times   \n",
       "8  http://www.calendarlive.com/movies/reviews/cl-...  Los Angeles Times   \n",
       "9   http://www.rogerebert.com/reviews/toy-story-1995  Chicago Sun-Times   \n",
       "\n",
       "                                               quote          review_date  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04 00:00:00   \n",
       "1                  The year's most inventive comedy.  2008-08-31 00:00:00   \n",
       "2  A winning animated feature that has something ...  2008-08-18 00:00:00   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09 00:00:00   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10 00:00:00   \n",
       "5  As Lion King did before it, Toy Story revived ...  2007-05-03 00:00:00   \n",
       "6  The film will probably be more fully appreciat...  2006-06-24 00:00:00   \n",
       "7  Children will enjoy a new take on the irresist...  2003-05-20 00:00:00   \n",
       "8  Although its computer-generated imagery is imp...  2001-02-13 00:00:00   \n",
       "9  The result is a visionary roller-coaster ride ...  2000-01-01 00:00:00   \n",
       "\n",
       "   rtid      title  \n",
       "0  9559  Toy Story  \n",
       "1  9559  Toy Story  \n",
       "2  9559  Toy Story  \n",
       "3  9559  Toy Story  \n",
       "4  9559  Toy Story  \n",
       "5  9559  Toy Story  \n",
       "6  9559  Toy Story  \n",
       "7  9559  Toy Story  \n",
       "8  9559  Toy Story  \n",
       "9  9559  Toy Story  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 5 rows in the dataset\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13432</th>\n",
       "      <td>Rita Kempley</td>\n",
       "      <td>rotten</td>\n",
       "      <td>104389</td>\n",
       "      <td>http://www.washingtonpost.com/wp-srv/style/lon...</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>This anti-feminist parable is both a labor and...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>14013</td>\n",
       "      <td>The Hand That Rocks the Cradle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13433</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>88683</td>\n",
       "      <td>http://www.time.com/time/magazine/article/0,91...</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>All three stars do smart, honorable work.</td>\n",
       "      <td>2013-05-08 00:00:00</td>\n",
       "      <td>11917</td>\n",
       "      <td>Agnes of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13434</th>\n",
       "      <td>Kevin Thomas</td>\n",
       "      <td>rotten</td>\n",
       "      <td>88683</td>\n",
       "      <td>http://articles.latimes.com/1985-09-13/enterta...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>While Agnes of God has been considerably opene...</td>\n",
       "      <td>2013-05-08 00:00:00</td>\n",
       "      <td>11917</td>\n",
       "      <td>Agnes of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13435</th>\n",
       "      <td>Dave Kehr</td>\n",
       "      <td>rotten</td>\n",
       "      <td>88683</td>\n",
       "      <td>http://www.chicagoreader.com/chicago/agnes-of-...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>Despite all the anguished huffing and puffing,...</td>\n",
       "      <td>2013-05-08 00:00:00</td>\n",
       "      <td>11917</td>\n",
       "      <td>Agnes of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13436</th>\n",
       "      <td>Jay Boyar</td>\n",
       "      <td>fresh</td>\n",
       "      <td>88683</td>\n",
       "      <td>http://articles.orlandosentinel.com/1985-10-30...</td>\n",
       "      <td>Orlando Sentinel</td>\n",
       "      <td>It is Meg Tilly who makes the movie live. Her ...</td>\n",
       "      <td>2013-05-08 00:00:00</td>\n",
       "      <td>11917</td>\n",
       "      <td>Agnes of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13437</th>\n",
       "      <td>Gene Siskel</td>\n",
       "      <td>rotten</td>\n",
       "      <td>88683</td>\n",
       "      <td>http://articles.chicagotribune.com/1985-09-13/...</td>\n",
       "      <td>Chicago Tribune</td>\n",
       "      <td>Agnes of God plays with some challenging ideas...</td>\n",
       "      <td>2013-05-08 00:00:00</td>\n",
       "      <td>11917</td>\n",
       "      <td>Agnes of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13438</th>\n",
       "      <td>Variety Staff</td>\n",
       "      <td>rotten</td>\n",
       "      <td>88683</td>\n",
       "      <td>http://www.variety.com/review/VE1117796703.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>Fonda's relentless interrogating, mannered cha...</td>\n",
       "      <td>2008-10-18 00:00:00</td>\n",
       "      <td>11917</td>\n",
       "      <td>Agnes of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13439</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>88683</td>\n",
       "      <td>http://www.timeout.com/film/reviews/77605/agne...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>Splendidly shot by Sven Nykvist and with excel...</td>\n",
       "      <td>2006-06-24 00:00:00</td>\n",
       "      <td>11917</td>\n",
       "      <td>Agnes of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13440</th>\n",
       "      <td>Janet Maslin</td>\n",
       "      <td>rotten</td>\n",
       "      <td>88683</td>\n",
       "      <td>http://movies.nytimes.com/movie/review?res=950...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Miss Tilly makes a radiant Agnes, and Miss Ban...</td>\n",
       "      <td>2003-05-20 00:00:00</td>\n",
       "      <td>11917</td>\n",
       "      <td>Agnes of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13441</th>\n",
       "      <td>Roger Ebert</td>\n",
       "      <td>rotten</td>\n",
       "      <td>88683</td>\n",
       "      <td>http://www.rogerebert.com/reviews/agnes-of-god...</td>\n",
       "      <td>Chicago Sun-Times</td>\n",
       "      <td>Although the movie deals in the basic material...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>11917</td>\n",
       "      <td>Agnes of God</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                critic   fresh    imdb  \\\n",
       "13432     Rita Kempley  rotten  104389   \n",
       "13433  Richard Corliss   fresh   88683   \n",
       "13434     Kevin Thomas  rotten   88683   \n",
       "13435        Dave Kehr  rotten   88683   \n",
       "13436        Jay Boyar   fresh   88683   \n",
       "13437      Gene Siskel  rotten   88683   \n",
       "13438    Variety Staff  rotten   88683   \n",
       "13439              NaN   fresh   88683   \n",
       "13440     Janet Maslin  rotten   88683   \n",
       "13441      Roger Ebert  rotten   88683   \n",
       "\n",
       "                                                    link        publication  \\\n",
       "13432  http://www.washingtonpost.com/wp-srv/style/lon...    Washington Post   \n",
       "13433  http://www.time.com/time/magazine/article/0,91...      TIME Magazine   \n",
       "13434  http://articles.latimes.com/1985-09-13/enterta...  Los Angeles Times   \n",
       "13435  http://www.chicagoreader.com/chicago/agnes-of-...     Chicago Reader   \n",
       "13436  http://articles.orlandosentinel.com/1985-10-30...   Orlando Sentinel   \n",
       "13437  http://articles.chicagotribune.com/1985-09-13/...    Chicago Tribune   \n",
       "13438  http://www.variety.com/review/VE1117796703.htm...            Variety   \n",
       "13439  http://www.timeout.com/film/reviews/77605/agne...           Time Out   \n",
       "13440  http://movies.nytimes.com/movie/review?res=950...     New York Times   \n",
       "13441  http://www.rogerebert.com/reviews/agnes-of-god...  Chicago Sun-Times   \n",
       "\n",
       "                                                   quote          review_date  \\\n",
       "13432  This anti-feminist parable is both a labor and...  2000-01-01 00:00:00   \n",
       "13433          All three stars do smart, honorable work.  2013-05-08 00:00:00   \n",
       "13434  While Agnes of God has been considerably opene...  2013-05-08 00:00:00   \n",
       "13435  Despite all the anguished huffing and puffing,...  2013-05-08 00:00:00   \n",
       "13436  It is Meg Tilly who makes the movie live. Her ...  2013-05-08 00:00:00   \n",
       "13437  Agnes of God plays with some challenging ideas...  2013-05-08 00:00:00   \n",
       "13438  Fonda's relentless interrogating, mannered cha...  2008-10-18 00:00:00   \n",
       "13439  Splendidly shot by Sven Nykvist and with excel...  2006-06-24 00:00:00   \n",
       "13440  Miss Tilly makes a radiant Agnes, and Miss Ban...  2003-05-20 00:00:00   \n",
       "13441  Although the movie deals in the basic material...  2000-01-01 00:00:00   \n",
       "\n",
       "        rtid                           title  \n",
       "13432  14013  The Hand That Rocks the Cradle  \n",
       "13433  11917                    Agnes of God  \n",
       "13434  11917                    Agnes of God  \n",
       "13435  11917                    Agnes of God  \n",
       "13436  11917                    Agnes of God  \n",
       "13437  11917                    Agnes of God  \n",
       "13438  11917                    Agnes of God  \n",
       "13439  11917                    Agnes of God  \n",
       "13440  11917                    Agnes of God  \n",
       "13441  11917                    Agnes of God  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bottom 5 rows in the dataset\n",
    "print(data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13442, 9) \n",
      "\n",
      "critic         object\n",
      "fresh          object\n",
      "imdb            int64\n",
      "link           object\n",
      "publication    object\n",
      "quote          object\n",
      "review_date    object\n",
      "rtid            int64\n",
      "title          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Columns in the dataset\n",
    "print(data.shape, \"\\n\")\n",
    "\n",
    "#Types of columns\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['critic', 'fresh', 'imdb', 'link', 'publication', 'quote',\n",
      "       'review_date', 'rtid', 'title'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Variables in the dataset\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Number of missings for fresh and quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in fresh: 0\n",
      "Missing values in quote: 0\n"
     ]
    }
   ],
   "source": [
    "#Missings in fresh\n",
    "print(\"Missing values in fresh:\", data.fresh.isna().sum())\n",
    "\n",
    "#Missings in quote\n",
    "print(\"Missing values in quote:\", data.quote.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Different values for fresh/rotten evaluations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fresh', 'rotten', 'none'], dtype=object)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Different values of fresh\n",
    "data.fresh.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Counts and percentages of different fresh values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts and percentages of different fresh values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <td>8389</td>\n",
       "      <td>62.408868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>23</td>\n",
       "      <td>0.171105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotten</th>\n",
       "      <td>5030</td>\n",
       "      <td>37.420027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  percentage\n",
       "fresh                    \n",
       "fresh    8389   62.408868\n",
       "none       23    0.171105\n",
       "rotten   5030   37.420027"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Different fresh and rotten values\n",
    "print(\"Counts and percentages of different fresh values\")\n",
    "percentages=pd.DataFrame(data.groupby('fresh')['fresh'].count())\n",
    "percentages.columns=['count']\n",
    "percentages['percentage']=percentages.apply(lambda count: 100*count/float(count.sum()))\n",
    "percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) number of zero-length or only whitespace quote-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero-length values 0\n",
      "Length of quotes\n",
      "                                               quote  Length\n",
      "0  So ingenious in concept, design and execution ...     137\n",
      "1                  The year's most inventive comedy.      33\n",
      "2  A winning animated feature that has something ...      79\n",
      "3  The film sports a provocative and appealing st...     107\n",
      "4  An entertaining computer-generated, hyperreali...     110\n",
      "Num of white space quotes\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Number of zero-length value\n",
    "\n",
    "print('Number of zero-length values', (data.quote.apply(lambda x : len(x)) == 0).sum())\n",
    "\n",
    "\n",
    "#Number of white space values\n",
    "quotes=pd.DataFrame(data['quote'])\n",
    "quotes['Length']=quotes['quote'].str.len()\n",
    "\n",
    "\n",
    "print(\"Length of quotes\")\n",
    "print(quotes.head(5))\n",
    "\n",
    "print(\"Num of white space quotes\")\n",
    "print(quotes['quote'].str.isspace().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Minimum-maximum-average length of quotes (either in words, or in characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of characters :  256\n",
      "Minimum number of characters :  4\n",
      "Average number of characters :  121\n"
     ]
    }
   ],
   "source": [
    "#In terms of characters\n",
    "#Maximum length of quotes(in characters)\n",
    "print(\"Maximum number of characters : \",quotes['Length'].max())\n",
    "\n",
    "#Minimum length of quotes(in characters)\n",
    "print(\"Minimum number of characters : \", quotes['Length'].min())\n",
    "\n",
    "#Average number of characters\n",
    "avg=round(sum(quotes['Length'])/len(quotes['Length']))\n",
    "print(\"Average number of characters : \", avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length in terms of words: 49\n",
      "Minimum length in terms of words: 1\n",
      "Average length in terms of words: 20\n"
     ]
    }
   ],
   "source": [
    "#In terms of words\n",
    "#Maximum length of quotes(in words)\n",
    "split_quotes_max = len(max(quotes[\"quote\"].str.split(\" \").to_list(), key=len))\n",
    "print(\"Maximum length in terms of words:\", split_quotes_max)\n",
    "\n",
    "\n",
    "#Minimum length of quotes(in words)\n",
    "split_quotes_min = len(min(quotes[\"quote\"].str.split(\" \").to_list(), key=len))\n",
    "print(\"Minimum length in terms of words:\", split_quotes_min)\n",
    "\n",
    "\n",
    "\n",
    "#Average number of words\n",
    "print(\"Average length in terms of words:\", \n",
    "      round(sum(map(len,quotes[\"quote\"].str.split(\" \") ))/len(quotes[\"quote\"].str.split(\" \"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f)  How many reviews are in data multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mult_reviews = (data.groupby('quote', as_index = False).size().\n",
    "                sort_values(ascending = False).reset_index(name = 'Count of occurences'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['quote', 'count'], dtype='object')"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult_reviews.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of occurences is indicating the number of times a quote occurs. Number of quotes indicates how many quotes are being repeated. 1 quote occurs 4 times, 45 quotes appear 3 times, 513 quotes occur twice and 12277 quotes occur once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  counts\n",
       "0      4       1\n",
       "1      3      45\n",
       "2      2     513\n",
       "3      1   12277"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult_reviews.groupby('Count of occurences', as_index = False).size().sort_values().reset_index(name = 'Number of quotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.timeout.com/film/reviews/87745/toy-...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.time.com/time/magazine/article/0,91...</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.newsweek.com/id/104199</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.variety.com/review/VE1117941294.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://onfilm.chicagoreader.com/movies/capsule...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb  \\\n",
       "0         Derek Adams  fresh  114709   \n",
       "1     Richard Corliss  fresh  114709   \n",
       "2         David Ansen  fresh  114709   \n",
       "3       Leonard Klady  fresh  114709   \n",
       "4  Jonathan Rosenbaum  fresh  114709   \n",
       "\n",
       "                                                link     publication  \\\n",
       "0  http://www.timeout.com/film/reviews/87745/toy-...        Time Out   \n",
       "1  http://www.time.com/time/magazine/article/0,91...   TIME Magazine   \n",
       "2                  http://www.newsweek.com/id/104199        Newsweek   \n",
       "3  http://www.variety.com/review/VE1117941294.htm...         Variety   \n",
       "4  http://onfilm.chicagoreader.com/movies/capsule...  Chicago Reader   \n",
       "\n",
       "                                               quote          review_date  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04 00:00:00   \n",
       "1                  The year's most inventive comedy.  2008-08-31 00:00:00   \n",
       "2  A winning animated feature that has something ...  2008-08-18 00:00:00   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09 00:00:00   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10 00:00:00   \n",
       "\n",
       "   rtid      title  \n",
       "0  9559  Toy Story  \n",
       "1  9559  Toy Story  \n",
       "2  9559  Toy Story  \n",
       "3  9559  Toy Story  \n",
       "4  9559  Toy Story  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['fresh'] != 'none']\n",
    "data = data.drop_duplicates()\n",
    "data = data.reset_index()\n",
    "data = data.drop(columns = 'index')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping NA values if any in the fresh and quote column\n",
    "def CheckInconsistency (dataset,variable1, variable2):\n",
    "    # check if variable 1 and variable 2 are not missing.\n",
    "    #print(variable1)\n",
    "    if ((dataset[variable1].isna().sum()>0 ) | (dataset[variable1].isnull().sum()>0) |(dataset[variable2].isna().sum()>0 )|(dataset[variable2].isnull().sum()>0)):\n",
    "        print('There are inconsistencies. hence dropping the null and NA values.')\n",
    "        dataset=dataset[variable1].dropna()\n",
    "        dataset=dataset[variable2].dropna()\n",
    "    else:\n",
    "        print('There are no inconsistencies in '+ variable1 + ' and ' + variable2 + ' columns')\n",
    "    \n",
    "    #check if quote is not an empty string\n",
    "    if ((dataset[variable1].empty == True) | ((dataset[variable1]== '').sum()>0) | (dataset[variable1].astype(str).str.isspace().sum())):\n",
    "        print('There are empty syring values ')\n",
    "        \n",
    "        a=dataset[dataset[variable1]==''].index\n",
    "        dataset.drop(dataset.index(a))\n",
    "    else:\n",
    "        print('There are no empty values ')\n",
    "    \n",
    "    #Drop the duplicate values\n",
    "    \n",
    "    # keep first duplicate row\n",
    "    dataset = dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the stopwords and removing numbers, punctuations , whitespaces\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def quote_to_words(raw_quote):\n",
    "    #removing raw letters,numbers,punctuations\n",
    "    letters = re.sub(\"[^a-zA-Z]\",\" \",raw_quote)\n",
    "    #creating an array , resolving whitespaces\n",
    "    words = letters.lower().split()\n",
    "    #create an array of stopwords so that we don't have to access corpus to search for a stopword\n",
    "    stop = set(stopwords.words(\"english\"))\n",
    "    #removing stopwords from the raw_review\n",
    "    meaningful_words = [w for w in words if w not in stop]\n",
    "    #return a string with only the words that are important\n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no inconsistencies in fresh and quote columns\n",
      "There are no empty values \n"
     ]
    }
   ],
   "source": [
    "CheckInconsistency(data, 'fresh' , 'quote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_quotes = []\n",
    "\n",
    "for i in range(data.quote.size):\n",
    "    clean_quotes.append(quote_to_words(data.quote[i]))\n",
    "\n",
    "\n",
    "quotes_series = pd.Series(clean_quotes)\n",
    "\n",
    "#Creating work data\n",
    "work_data = pd.DataFrame(quotes_series)\n",
    "\n",
    "#Combining the fresh and quotes columns\n",
    "work_data.rename(columns = {0 : 'quote'}, inplace = True)\n",
    "\n",
    "#Appending the fresh column\n",
    "work_data['fresh'] = data.fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12823, 2)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of quotes\n",
    "work_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20492"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Implementing vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary = True)\n",
    "X = vectorizer.fit_transform(clean_quotes).toarray()\n",
    "X.shape\n",
    "\n",
    "\n",
    "y = data[['fresh']] # Target\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "#Number of unique words\n",
    "len(set(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train and test models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.48165241862569685\n",
      "-0.961711165656882\n"
     ]
    }
   ],
   "source": [
    "#Calculating probabilities of fresh and rotten with log probabilities\n",
    "prob_fresh = y_train.fresh[y_train.fresh == 'fresh'].count()/len(y_train)\n",
    "prob_rotten = 1 - prob_fresh\n",
    "\n",
    "log_prob_fresh = np.log(prob_fresh)\n",
    "log_prob_rotten = np.log(prob_rotten)\n",
    "print(log_prob_fresh)\n",
    "print(log_prob_rotten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roshn\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train.reset_index(inplace= True)\n",
    "y_train.drop(columns = 'index', inplace = True)\n",
    "\n",
    "\n",
    "#Calculating the probabilities of words given fresh\n",
    "\n",
    "index_fresh = y_train[y_train['fresh'] == 'fresh'].index\n",
    "X_train_fresh = X_train[index_fresh].sum(axis = 0)\n",
    "prob_w_f = X_train_fresh/len(y_train[y_train['fresh'] == 'fresh'])\n",
    "\n",
    "\n",
    "#Calculating conditional probabilites for Word|Rotten \n",
    "index_rotten = y_train[y_train['fresh'] == 'rotten'].index\n",
    "X_train_rotten = X_train[index_rotten].sum(axis = 0)\n",
    "prob_w_r = X_train_rotten/len(y_train[y_train['fresh'] == 'rotten'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserting the calculated prob P(W|R) and P(W|F) into rotten and fresh df as all set of words as columns\n",
    "fresh = pd.DataFrame(pd.Series(words)).reset_index()\n",
    "fresh.drop(columns = 'index', inplace = True)\n",
    "fresh['prob_w_f'] = prob_w_f\n",
    "\n",
    "rotten = pd.DataFrame(pd.Series(words)).reset_index()\n",
    "rotten.drop(columns = 'index', inplace = True)\n",
    "rotten['prob_w_r'] = prob_w_r\n",
    "\n",
    "fresh.rename(columns = {0 : 'words', 'prob_w_f' : 'Pr(W|F)'}, inplace = True)\n",
    "rotten.rename(columns = {0 : 'words', 'prob_w_r' : 'Pr(W|R)'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Pr(W|F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14621</th>\n",
       "      <td>regenerate</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14615</th>\n",
       "      <td>regains</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>facetiousness</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14612</th>\n",
       "      <td>refused</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6294</th>\n",
       "      <td>facilitate</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607</th>\n",
       "      <td>refried</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>facing</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14604</th>\n",
       "      <td>refrained</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602</th>\n",
       "      <td>reformation</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20491</th>\n",
       "      <td>zzzzzzzzz</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               words  Pr(W|F)\n",
       "14621     regenerate      0.0\n",
       "14615        regains      0.0\n",
       "6290   facetiousness      0.0\n",
       "14612        refused      0.0\n",
       "6294      facilitate      0.0\n",
       "14607        refried      0.0\n",
       "6296          facing      0.0\n",
       "14604      refrained      0.0\n",
       "14602    reformation      0.0\n",
       "20491      zzzzzzzzz      0.0"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh.sort_values(by = 'Pr(W|F)', ascending  = False).head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Pr(W|R)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9450</th>\n",
       "      <td>inventor</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9451</th>\n",
       "      <td>inversion</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9455</th>\n",
       "      <td>investigated</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9457</th>\n",
       "      <td>investigations</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9459</th>\n",
       "      <td>investiture</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9461</th>\n",
       "      <td>investors</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9463</th>\n",
       "      <td>inveterate</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9465</th>\n",
       "      <td>invigorating</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9466</th>\n",
       "      <td>invigoratingly</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10246</th>\n",
       "      <td>lehman</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                words  Pr(W|R)\n",
       "9450         inventor      0.0\n",
       "9451        inversion      0.0\n",
       "9455     investigated      0.0\n",
       "9457   investigations      0.0\n",
       "9459      investiture      0.0\n",
       "9461        investors      0.0\n",
       "9463       inveterate      0.0\n",
       "9465     invigorating      0.0\n",
       "9466   invigoratingly      0.0\n",
       "10246          lehman      0.0"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten.sort_values(by = 'Pr(W|R)', ascending  = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words      0\n",
      "Pr(W|R)    0\n",
      "dtype: int64\n",
      "words      0\n",
      "Pr(W|F)    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rotten.isna().sum())\n",
    "print(fresh.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating log probabilities\n",
    "#Log likelihood of Pr(W|F)\n",
    "fresh['log_Pr_W_F']=c['Pr(W|F)'].apply(lambda x: np.log(x))\n",
    "\n",
    "\n",
    "#Log likelihood of Pr(W|R)\n",
    "rotten['log_Pr_W_R']=c['Pr(W|R)'].apply(lambda x: np.log(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Pr(W|F)</th>\n",
       "      <th>log_Pr_W_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaron</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>-7.655548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abbott</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abbreviated</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abduct</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abe</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>abiding</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>abilities</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ability</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>-6.046111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>able</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>-5.809722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ably</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>-7.144723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aboard</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>abounce</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>abound</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>abounds</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>abrams</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>abroad</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>abruptly</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>absence</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>-7.367866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>absolute</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>-7.144723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>-6.269254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>absorbed</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>-7.367866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>absorbing</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>-5.663118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>absorbingly</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>absorption</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>-7.144723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>abstraction</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>absurd</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>-7.144723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20450</th>\n",
       "      <td>zestfully</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20451</th>\n",
       "      <td>zesty</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20452</th>\n",
       "      <td>zeta</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20453</th>\n",
       "      <td>zhang</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20454</th>\n",
       "      <td>zhivago</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20455</th>\n",
       "      <td>ziggurats</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20456</th>\n",
       "      <td>zigs</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20459</th>\n",
       "      <td>zillion</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20463</th>\n",
       "      <td>zingers</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20464</th>\n",
       "      <td>zings</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20465</th>\n",
       "      <td>zingy</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20466</th>\n",
       "      <td>zinnemann</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20467</th>\n",
       "      <td>zinner</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20468</th>\n",
       "      <td>zip</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20471</th>\n",
       "      <td>zippy</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>-7.367866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20472</th>\n",
       "      <td>zips</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20473</th>\n",
       "      <td>zirconium</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20474</th>\n",
       "      <td>zoe</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>zombies</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>zombified</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>zonca</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>zone</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>-7.655548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20481</th>\n",
       "      <td>zoological</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20483</th>\n",
       "      <td>zooming</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>zooms</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20485</th>\n",
       "      <td>zorro</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20486</th>\n",
       "      <td>zorros</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20487</th>\n",
       "      <td>zowie</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-8.754161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20488</th>\n",
       "      <td>zucker</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20490</th>\n",
       "      <td>zwick</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-8.061014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14151 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             words   Pr(W|F)  log_Pr_W_F\n",
       "0            aaron  0.000473   -7.655548\n",
       "1          abandon  0.000158   -8.754161\n",
       "2        abandoned  0.000158   -8.754161\n",
       "3      abandonment  0.000158   -8.754161\n",
       "5           abbott  0.000316   -8.061014\n",
       "6      abbreviated  0.000158   -8.754161\n",
       "8           abduct  0.000158   -8.754161\n",
       "9              abe  0.000316   -8.061014\n",
       "12         abiding  0.000158   -8.754161\n",
       "13       abilities  0.000316   -8.061014\n",
       "14         ability  0.002367   -6.046111\n",
       "17            able  0.002998   -5.809722\n",
       "19            ably  0.000789   -7.144723\n",
       "20          aboard  0.000316   -8.061014\n",
       "24         abounce  0.000158   -8.754161\n",
       "25          abound  0.000316   -8.061014\n",
       "26         abounds  0.000316   -8.061014\n",
       "27          abrams  0.000158   -8.754161\n",
       "29          abroad  0.000158   -8.754161\n",
       "31        abruptly  0.000158   -8.754161\n",
       "32         absence  0.000631   -7.367866\n",
       "34        absolute  0.000789   -7.144723\n",
       "35      absolutely  0.001894   -6.269254\n",
       "36        absorbed  0.000631   -7.367866\n",
       "37       absorbing  0.003472   -5.663118\n",
       "38     absorbingly  0.000158   -8.754161\n",
       "39      absorption  0.000158   -8.754161\n",
       "41        abstract  0.000789   -7.144723\n",
       "42     abstraction  0.000316   -8.061014\n",
       "44          absurd  0.000789   -7.144723\n",
       "...            ...       ...         ...\n",
       "20450    zestfully  0.000158   -8.754161\n",
       "20451        zesty  0.000316   -8.061014\n",
       "20452         zeta  0.000158   -8.754161\n",
       "20453        zhang  0.000158   -8.754161\n",
       "20454      zhivago  0.000158   -8.754161\n",
       "20455    ziggurats  0.000158   -8.754161\n",
       "20456         zigs  0.000158   -8.754161\n",
       "20459      zillion  0.000316   -8.061014\n",
       "20463      zingers  0.000316   -8.061014\n",
       "20464        zings  0.000158   -8.754161\n",
       "20465        zingy  0.000158   -8.754161\n",
       "20466    zinnemann  0.000316   -8.061014\n",
       "20467       zinner  0.000158   -8.754161\n",
       "20468          zip  0.000316   -8.061014\n",
       "20471        zippy  0.000631   -7.367866\n",
       "20472         zips  0.000158   -8.754161\n",
       "20473    zirconium  0.000158   -8.754161\n",
       "20474          zoe  0.000158   -8.754161\n",
       "20476      zombies  0.000158   -8.754161\n",
       "20477    zombified  0.000158   -8.754161\n",
       "20478        zonca  0.000158   -8.754161\n",
       "20479         zone  0.000473   -7.655548\n",
       "20481   zoological  0.000158   -8.754161\n",
       "20483      zooming  0.000158   -8.754161\n",
       "20484        zooms  0.000158   -8.754161\n",
       "20485        zorro  0.000316   -8.061014\n",
       "20486       zorros  0.000158   -8.754161\n",
       "20487        zowie  0.000158   -8.754161\n",
       "20488       zucker  0.000316   -8.061014\n",
       "20490        zwick  0.000316   -8.061014\n",
       "\n",
       "[14151 rows x 3 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing inf and -inf probability values\n",
    "fresh = fresh.replace(to_replace = [np.inf, -np.inf], value = [np.nan, np.nan]).dropna()\n",
    "fresh.head(5)\n",
    "\n",
    "rotten = rotten.replace(to_replace = [np.inf, -np.inf], value = [np.nan, np.nan]).dropna()\n",
    "rotten.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fresh Log Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abe</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 20492 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  abandon  abandoned  abandonment  abandons  abbott  abbreviated  \\\n",
       "0      0        0          0            0         0       0            0   \n",
       "1      0        0          0            0         0       0            0   \n",
       "2      0        0          0            0         0       0            0   \n",
       "3      0        0          0            0         0       0            0   \n",
       "4      0        0          0            0         0       0            0   \n",
       "\n",
       "   abdominal  abduct  abe  ...  zoom  zooming  zooms  zorro  zorros  zowie  \\\n",
       "0          0       0    0  ...     0        0      0      0       0      0   \n",
       "1          0       0    0  ...     0        0      0      0       0      0   \n",
       "2          0       0    0  ...     0        0      0      0       0      0   \n",
       "3          0       0    0  ...     0        0      0      0       0      0   \n",
       "4          0       0    0  ...     0        0      0      0       0      0   \n",
       "\n",
       "   zucker  zweibel  zwick  zzzzzzzzz  \n",
       "0       0        0      0          0  \n",
       "1       0        0      0          0  \n",
       "2       0        0      0          0  \n",
       "3       0        0      0          0  \n",
       "4       0        0      0          0  \n",
       "\n",
       "[5 rows x 20492 columns]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe with vectorized test words\n",
    "test_words_df = pd.DataFrame(X_test, columns = words)\n",
    "test_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transposing fresh\n",
    "fresh_T =  fresh.T\n",
    "fresh_T.columns = fresh_T.iloc[0]\n",
    "fresh_T.drop(['words', 'Pr(W|F)'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>words</th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abe</th>\n",
       "      <th>abiding</th>\n",
       "      <th>abilities</th>\n",
       "      <th>...</th>\n",
       "      <th>zonca</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zwick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log_Pr_W_F</th>\n",
       "      <td>-7.65555</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-8.06101</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-8.06101</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-8.06101</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-7.65555</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-8.06101</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-8.75416</td>\n",
       "      <td>-8.06101</td>\n",
       "      <td>-8.06101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 14151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "words         aaron  abandon abandoned abandonment   abbott abbreviated  \\\n",
       "log_Pr_W_F -7.65555 -8.75416  -8.75416    -8.75416 -8.06101    -8.75416   \n",
       "\n",
       "words        abduct      abe  abiding abilities  ...    zonca     zone  \\\n",
       "log_Pr_W_F -8.75416 -8.06101 -8.75416  -8.06101  ... -8.75416 -7.65555   \n",
       "\n",
       "words      zoological  zooming    zooms    zorro   zorros    zowie   zucker  \\\n",
       "log_Pr_W_F   -8.75416 -8.75416 -8.75416 -8.06101 -8.75416 -8.75416 -8.06101   \n",
       "\n",
       "words         zwick  \n",
       "log_Pr_W_F -8.06101  \n",
       "\n",
       "[1 rows x 14151 columns]"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying fresh\n",
    "fresh_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abe</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>log_fresh_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-57.607070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-84.184092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-61.345003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-99.249476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-102.630409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 20493 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  abandon  abandoned  abandonment  abandons  abbott  abbreviated  \\\n",
       "0      0        0          0            0         0       0            0   \n",
       "1      0        0          0            0         0       0            0   \n",
       "2      0        0          0            0         0       0            0   \n",
       "3      0        0          0            0         0       0            0   \n",
       "4      0        0          0            0         0       0            0   \n",
       "\n",
       "   abdominal  abduct  abe  ...  zooming  zooms  zorro  zorros  zowie  zucker  \\\n",
       "0          0       0    0  ...        0      0      0       0      0       0   \n",
       "1          0       0    0  ...        0      0      0       0      0       0   \n",
       "2          0       0    0  ...        0      0      0       0      0       0   \n",
       "3          0       0    0  ...        0      0      0       0      0       0   \n",
       "4          0       0    0  ...        0      0      0       0      0       0   \n",
       "\n",
       "   zweibel  zwick  zzzzzzzzz  log_fresh_pred  \n",
       "0        0      0          0      -57.607070  \n",
       "1        0      0          0      -84.184092  \n",
       "2        0      0          0      -61.345003  \n",
       "3        0      0          0      -99.249476  \n",
       "4        0      0          0     -102.630409  \n",
       "\n",
       "[5 rows x 20493 columns]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the log likelihoods for each of the words for fresh\n",
    "log_word_fresh_list = fresh_T.loc['log_Pr_W_F']\n",
    "log_word_fresh = pd.DataFrame(columns = test_words_df.columns)\n",
    "log_word_fresh = log_word_fresh.append(log_word_fresh_list)\n",
    "log_word_fresh.replace(np.nan, 0, inplace = True)\n",
    "\n",
    "test_words_df['log_fresh_pred'] = test_words_df.apply(lambda x : x* log_word_fresh.loc['log_Pr_W_F'] ,axis = 1).sum(axis = 1)\n",
    "test_words_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>words</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>abets</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abominable</th>\n",
       "      <th>abomination</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abounds</th>\n",
       "      <th>...</th>\n",
       "      <th>zingy</th>\n",
       "      <th>zinnemann</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippo</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log_Pr_W_R</th>\n",
       "      <td>-7.58095</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-7.58095</td>\n",
       "      <td>-6.07688</td>\n",
       "      <td>-5.7892</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-6.32819</td>\n",
       "      <td>-6.07688</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-8.2741</td>\n",
       "      <td>-8.2741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 11303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "words       abandon abandons abdominal    abets  ability    able abominable  \\\n",
       "log_Pr_W_R -7.58095  -8.2741   -8.2741 -7.58095 -6.07688 -5.7892    -8.2741   \n",
       "\n",
       "words      abomination abortion abounds  ...   zingy zinnemann  zipper  \\\n",
       "log_Pr_W_R     -8.2741  -8.2741 -8.2741  ... -8.2741   -8.2741 -8.2741   \n",
       "\n",
       "words        zippo   zombie     zone    zoom zweibel   zwick zzzzzzzzz  \n",
       "log_Pr_W_R -8.2741 -6.32819 -6.07688 -8.2741 -8.2741 -8.2741   -8.2741  \n",
       "\n",
       "[1 rows x 11303 columns]"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transposing rotten\n",
    "rotten_T =  rotten.T\n",
    "rotten_T.columns = rotten_T.iloc[0]\n",
    "rotten_T.drop(['words', 'Pr(W|R)'], inplace = True)\n",
    "rotten_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abe</th>\n",
       "      <th>...</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>log_fresh_pred</th>\n",
       "      <th>log_rotten_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-57.607070</td>\n",
       "      <td>-57.186279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-84.184092</td>\n",
       "      <td>-80.254668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-61.345003</td>\n",
       "      <td>-56.089703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-99.249476</td>\n",
       "      <td>-104.273027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-102.630409</td>\n",
       "      <td>-101.680242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 20494 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  abandon  abandoned  abandonment  abandons  abbott  abbreviated  \\\n",
       "0      0        0          0            0         0       0            0   \n",
       "1      0        0          0            0         0       0            0   \n",
       "2      0        0          0            0         0       0            0   \n",
       "3      0        0          0            0         0       0            0   \n",
       "4      0        0          0            0         0       0            0   \n",
       "\n",
       "   abdominal  abduct  abe  ...  zooms  zorro  zorros  zowie  zucker  zweibel  \\\n",
       "0          0       0    0  ...      0      0       0      0       0        0   \n",
       "1          0       0    0  ...      0      0       0      0       0        0   \n",
       "2          0       0    0  ...      0      0       0      0       0        0   \n",
       "3          0       0    0  ...      0      0       0      0       0        0   \n",
       "4          0       0    0  ...      0      0       0      0       0        0   \n",
       "\n",
       "   zwick  zzzzzzzzz  log_fresh_pred  log_rotten_pred  \n",
       "0      0          0      -57.607070       -57.186279  \n",
       "1      0          0      -84.184092       -80.254668  \n",
       "2      0          0      -61.345003       -56.089703  \n",
       "3      0          0      -99.249476      -104.273027  \n",
       "4      0          0     -102.630409      -101.680242  \n",
       "\n",
       "[5 rows x 20494 columns]"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the log likelihoods for each of the words for rotten\n",
    "log_word_rotten_list = rotten_T.loc['log_Pr_W_R']\n",
    "log_word_rotten = pd.DataFrame(columns = test_words_df.columns)\n",
    "log_word_rotten = log_word_rotten.append(log_word_rotten_list)\n",
    "log_word_rotten.replace(np.nan, 0, inplace = True)\n",
    "\n",
    "test_words_df['log_rotten_pred'] = (test_words_df.\n",
    "                                    apply(lambda x : x* log_word_rotten.loc['log_Pr_W_R'] ,axis = 1).sum(axis = 1))\n",
    "test_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abe</th>\n",
       "      <th>...</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>log_fresh_pred</th>\n",
       "      <th>log_rotten_pred</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-57.607070</td>\n",
       "      <td>-57.186279</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-84.184092</td>\n",
       "      <td>-80.254668</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-61.345003</td>\n",
       "      <td>-56.089703</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-99.249476</td>\n",
       "      <td>-104.273027</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-102.630409</td>\n",
       "      <td>-101.680242</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 20495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  abandon  abandoned  abandonment  abandons  abbott  abbreviated  \\\n",
       "0      0        0          0            0         0       0            0   \n",
       "1      0        0          0            0         0       0            0   \n",
       "2      0        0          0            0         0       0            0   \n",
       "3      0        0          0            0         0       0            0   \n",
       "4      0        0          0            0         0       0            0   \n",
       "\n",
       "   abdominal  abduct  abe  ...  zorro  zorros  zowie  zucker  zweibel  zwick  \\\n",
       "0          0       0    0  ...      0       0      0       0        0      0   \n",
       "1          0       0    0  ...      0       0      0       0        0      0   \n",
       "2          0       0    0  ...      0       0      0       0        0      0   \n",
       "3          0       0    0  ...      0       0      0       0        0      0   \n",
       "4          0       0    0  ...      0       0      0       0        0      0   \n",
       "\n",
       "   zzzzzzzzz  log_fresh_pred  log_rotten_pred  y_pred  \n",
       "0          0      -57.607070       -57.186279  rotten  \n",
       "1          0      -84.184092       -80.254668  rotten  \n",
       "2          0      -61.345003       -56.089703  rotten  \n",
       "3          0      -99.249476      -104.273027   fresh  \n",
       "4          0     -102.630409      -101.680242  rotten  \n",
       "\n",
       "[5 rows x 20495 columns]"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting whether test words belong to fresh or rotten based on log likelihoods\n",
    "test_words_df['y_pred'] = np.where((test_words_df['log_fresh_pred'] > test_words_df['log_rotten_pred']), 'fresh', 'rotten')\n",
    "test_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[639, 979],\n",
       "       [339, 608]], dtype=int64)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(y_test['fresh'], test_words_df['y_pred'])\n",
    "conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4861598440545809"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of fit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "accuracy_score(y_test['fresh'], test_words_df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38311279143037175"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision\n",
    "608/(608+979)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6420274551214361"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall\n",
    "608/(608+339)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20492, 2)"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words = test_words_df.drop(columns = ['log_fresh_pred', 'log_rotten_pred', 'y_pred'])\n",
    "freq_df = pd.DataFrame(test_words.sum().sort_values(ascending = False), columns = ['freq']).reset_index()\n",
    "freq_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>freq</th>\n",
       "      <th>words</th>\n",
       "      <th>Pr(W|F)</th>\n",
       "      <th>log_Pr_W_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film</td>\n",
       "      <td>398</td>\n",
       "      <td>film</td>\n",
       "      <td>0.163011</td>\n",
       "      <td>-1.813938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie</td>\n",
       "      <td>354</td>\n",
       "      <td>movie</td>\n",
       "      <td>0.130030</td>\n",
       "      <td>-2.039990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>217</td>\n",
       "      <td>one</td>\n",
       "      <td>0.088685</td>\n",
       "      <td>-2.422659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>149</td>\n",
       "      <td>like</td>\n",
       "      <td>0.043869</td>\n",
       "      <td>-3.126540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story</td>\n",
       "      <td>119</td>\n",
       "      <td>story</td>\n",
       "      <td>0.044501</td>\n",
       "      <td>-3.112254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>much</td>\n",
       "      <td>112</td>\n",
       "      <td>much</td>\n",
       "      <td>0.028089</td>\n",
       "      <td>-3.572377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>good</td>\n",
       "      <td>104</td>\n",
       "      <td>good</td>\n",
       "      <td>0.046868</td>\n",
       "      <td>-3.060429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comedy</td>\n",
       "      <td>97</td>\n",
       "      <td>comedy</td>\n",
       "      <td>0.034559</td>\n",
       "      <td>-3.365089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>even</td>\n",
       "      <td>94</td>\n",
       "      <td>even</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>-3.369666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>director</td>\n",
       "      <td>90</td>\n",
       "      <td>director</td>\n",
       "      <td>0.035032</td>\n",
       "      <td>-3.351483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  freq     words   Pr(W|F)  log_Pr_W_F\n",
       "0      film   398      film  0.163011   -1.813938\n",
       "1     movie   354     movie  0.130030   -2.039990\n",
       "2       one   217       one  0.088685   -2.422659\n",
       "3      like   149      like  0.043869   -3.126540\n",
       "4     story   119     story  0.044501   -3.112254\n",
       "5      much   112      much  0.028089   -3.572377\n",
       "6      good   104      good  0.046868   -3.060429\n",
       "7    comedy    97    comedy  0.034559   -3.365089\n",
       "8      even    94      even  0.034401   -3.369666\n",
       "9  director    90  director  0.035032   -3.351483"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conditional probability of word given fresh for most frequent words\n",
    "\n",
    "pd.merge(freq_df, fresh, left_on = 'index', right_on = 'words').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>freq</th>\n",
       "      <th>words</th>\n",
       "      <th>Pr(W|R)</th>\n",
       "      <th>log_Pr_W_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film</td>\n",
       "      <td>398</td>\n",
       "      <td>film</td>\n",
       "      <td>0.118847</td>\n",
       "      <td>-2.129916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie</td>\n",
       "      <td>354</td>\n",
       "      <td>movie</td>\n",
       "      <td>0.145116</td>\n",
       "      <td>-1.930222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>217</td>\n",
       "      <td>one</td>\n",
       "      <td>0.071155</td>\n",
       "      <td>-2.642890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>149</td>\n",
       "      <td>like</td>\n",
       "      <td>0.070645</td>\n",
       "      <td>-2.650084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story</td>\n",
       "      <td>119</td>\n",
       "      <td>story</td>\n",
       "      <td>0.042846</td>\n",
       "      <td>-3.150138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>much</td>\n",
       "      <td>112</td>\n",
       "      <td>much</td>\n",
       "      <td>0.053558</td>\n",
       "      <td>-2.926994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>good</td>\n",
       "      <td>104</td>\n",
       "      <td>good</td>\n",
       "      <td>0.041061</td>\n",
       "      <td>-3.192698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comedy</td>\n",
       "      <td>97</td>\n",
       "      <td>comedy</td>\n",
       "      <td>0.041826</td>\n",
       "      <td>-3.174236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>even</td>\n",
       "      <td>94</td>\n",
       "      <td>even</td>\n",
       "      <td>0.041571</td>\n",
       "      <td>-3.180352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>director</td>\n",
       "      <td>90</td>\n",
       "      <td>director</td>\n",
       "      <td>0.034940</td>\n",
       "      <td>-3.354121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  freq     words   Pr(W|R)  log_Pr_W_R\n",
       "0      film   398      film  0.118847   -2.129916\n",
       "1     movie   354     movie  0.145116   -1.930222\n",
       "2       one   217       one  0.071155   -2.642890\n",
       "3      like   149      like  0.070645   -2.650084\n",
       "4     story   119     story  0.042846   -3.150138\n",
       "5      much   112      much  0.053558   -2.926994\n",
       "6      good   104      good  0.041061   -3.192698\n",
       "7    comedy    97    comedy  0.041826   -3.174236\n",
       "8      even    94      even  0.041571   -3.180352\n",
       "9  director    90  director  0.034940   -3.354121"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conditional probability of word given rotten for most frequent words\n",
    "pd.merge(freq_df, rotten, left_on = 'index', right_on = 'words').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "film      165\n",
       "movie     133\n",
       "one        88\n",
       "like       52\n",
       "much       42\n",
       "comedy     40\n",
       "best       40\n",
       "story      40\n",
       "even       39\n",
       "good       36\n",
       "dtype: int64"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Most frequest fresh words\n",
    "test_fresh = (test_words_df[test_words_df['y_pred'] == 'fresh'].\n",
    "              drop(columns = ['log_fresh_pred', 'log_rotten_pred', 'y_pred']))\n",
    "test_fresh.sum().sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "film        233\n",
       "movie       221\n",
       "one         129\n",
       "like         97\n",
       "story        79\n",
       "much         70\n",
       "good         68\n",
       "comedy       57\n",
       "time         56\n",
       "director     55\n",
       "dtype: int64"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Most frequest rotten words\n",
    "test_rotten = (test_words_df[test_words_df['y_pred'] == 'rotten'].\n",
    "              drop(columns = ['log_fresh_pred', 'log_rotten_pred', 'y_pred']))\n",
    "test_rotten.sum().sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1 = y_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_index = test_words_df.y_pred[(test_words_df.y_pred == 'fresh')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978,)"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       rotten\n",
       "1       rotten\n",
       "2       rotten\n",
       "3        fresh\n",
       "4       rotten\n",
       "5        fresh\n",
       "6        fresh\n",
       "7        fresh\n",
       "8       rotten\n",
       "9        fresh\n",
       "10      rotten\n",
       "11      rotten\n",
       "12      rotten\n",
       "13      rotten\n",
       "14       fresh\n",
       "15      rotten\n",
       "16      rotten\n",
       "17       fresh\n",
       "18      rotten\n",
       "19       fresh\n",
       "20       fresh\n",
       "21       fresh\n",
       "22       fresh\n",
       "23       fresh\n",
       "24       fresh\n",
       "25      rotten\n",
       "26      rotten\n",
       "27      rotten\n",
       "28      rotten\n",
       "29       fresh\n",
       "         ...  \n",
       "2535    rotten\n",
       "2536    rotten\n",
       "2537    rotten\n",
       "2538     fresh\n",
       "2539    rotten\n",
       "2540    rotten\n",
       "2541     fresh\n",
       "2542     fresh\n",
       "2543    rotten\n",
       "2544     fresh\n",
       "2545    rotten\n",
       "2546     fresh\n",
       "2547    rotten\n",
       "2548    rotten\n",
       "2549     fresh\n",
       "2550     fresh\n",
       "2551    rotten\n",
       "2552    rotten\n",
       "2553    rotten\n",
       "2554    rotten\n",
       "2555    rotten\n",
       "2556     fresh\n",
       "2557    rotten\n",
       "2558     fresh\n",
       "2559    rotten\n",
       "2560    rotten\n",
       "2561    rotten\n",
       "2562    rotten\n",
       "2563    rotten\n",
       "2564    rotten\n",
       "Name: y_pred, Length: 2565, dtype: object"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words_df.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclass = test_words_df[y_test1.fresh != test_words_df.y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abe</th>\n",
       "      <th>...</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>log_fresh_pred</th>\n",
       "      <th>log_rotten_pred</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-57.607070</td>\n",
       "      <td>-57.186279</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-84.184092</td>\n",
       "      <td>-80.254668</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-61.345003</td>\n",
       "      <td>-56.089703</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-74.949268</td>\n",
       "      <td>-69.152084</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-78.233160</td>\n",
       "      <td>-73.761263</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 20495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aaron  abandon  abandoned  abandonment  abandons  abbott  abbreviated  \\\n",
       "0       0        0          0            0         0       0            0   \n",
       "1       0        0          0            0         0       0            0   \n",
       "2       0        0          0            0         0       0            0   \n",
       "10      0        0          0            0         0       0            0   \n",
       "11      0        0          0            0         0       0            0   \n",
       "\n",
       "    abdominal  abduct  abe  ...  zorro  zorros  zowie  zucker  zweibel  zwick  \\\n",
       "0           0       0    0  ...      0       0      0       0        0      0   \n",
       "1           0       0    0  ...      0       0      0       0        0      0   \n",
       "2           0       0    0  ...      0       0      0       0        0      0   \n",
       "10          0       0    0  ...      0       0      0       0        0      0   \n",
       "11          0       0    0  ...      0       0      0       0        0      0   \n",
       "\n",
       "    zzzzzzzzz  log_fresh_pred  log_rotten_pred  y_pred  \n",
       "0           0      -57.607070       -57.186279  rotten  \n",
       "1           0      -84.184092       -80.254668  rotten  \n",
       "2           0      -61.345003       -56.089703  rotten  \n",
       "10          0      -74.949268       -69.152084  rotten  \n",
       "11          0      -78.233160       -73.761263  rotten  \n",
       "\n",
       "[5 rows x 20495 columns]"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Misclassified words\n",
    "\n",
    "misclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7386</th>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086</th>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fresh\n",
       "7386    fresh\n",
       "10086   fresh\n",
       "3037    fresh\n",
       "3026    fresh\n",
       "2692   rotten\n",
       "10207   fresh\n",
       "11847   fresh\n",
       "3404    fresh\n",
       "3299   rotten\n",
       "3082    fresh\n",
       "2252    fresh\n",
       "4148    fresh"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7386     Dark, funny, paranoid, arbitrary, humming with...\n",
       "10086    Miller is outstanding as a father who is utter...\n",
       "3037     In tandem, the director and screenwriter build...\n",
       "2252     A splashy, volatile, crowd- pleasing rock-star...\n",
       "4148     Mr. Black's screenplay is mean-spirited, but i...\n",
       "Name: quote, dtype: object"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [7386, 10086, 3037, 2252, 4148]\n",
    "data.loc[list].quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7386  dark funny paranoid arbitrary humming tamped eroticism love things weird good news\n",
      "10086  miller outstanding father utterly convinced dating first step towards instant complete moral sexual decay\n",
      "3037  tandem director screenwriter build palpable suspense boy rivet raising issues forgiveness deserves\n",
      "2252  splashy volatile crowd pleasing rock star melodrama makes sheer emotional wallop sometimes lacks finesse\n",
      "4148  mr black screenplay mean spirited earns keep sharp sarcastic dialogue ingenious ways setting story\n"
     ]
    }
   ],
   "source": [
    "#List of misclassified quotes\n",
    "for i in list:\n",
    "    print(i, \"\", clean_quotes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On observig the log likelihoods of these misclassified words for fresh and rotten, we observe that they are more or less same and there's not much difference. Since it is observed that the log likelihood of these words is more for rotten , that's why the model has predicted it as rotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_fresh_pred</th>\n",
       "      <th>log_rotten_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-57.607070</td>\n",
       "      <td>-57.186279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-84.184092</td>\n",
       "      <td>-80.254668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-61.345003</td>\n",
       "      <td>-56.089703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-74.949268</td>\n",
       "      <td>-69.152084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-78.233160</td>\n",
       "      <td>-73.761263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    log_fresh_pred  log_rotten_pred\n",
       "0       -57.607070       -57.186279\n",
       "1       -84.184092       -80.254668\n",
       "2       -61.345003       -56.089703\n",
       "10      -74.949268       -69.152084\n",
       "11      -78.233160       -73.761263"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words_df.loc[[0,1,2,10,11]][['log_fresh_pred', 'log_rotten_pred']]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  NB with smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Create two functions: one for fitting NB model, and another to predict outcome based on the \u001c",
    "tted model. As mentioned above, the model is fully described with 4 probabilities, so your fitting function may return such a list as the model; and the prediction function may take it as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing and cleaning function\n",
    "def pre_processing_and_cleaning(file):\n",
    "    data=pd.read_csv(file)\n",
    "    data = data[data['fresh'] != 'none']\n",
    "    data = data.drop_duplicates()\n",
    "    data = data.drop(columns = 'index')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_to_words(raw_quote):\n",
    "        import re\n",
    "        from nltk.corpus import stopwords\n",
    "        #removing raw letters,numbers,punctuations\n",
    "        letters = re.sub(\"[^a-zA-Z]\",\" \",raw_quote)\n",
    "        #creating an array , resolving whitespaces\n",
    "        words = letters.lower().split()\n",
    "        #create an array of stopwords so that we don't have to access corpus to search for a stopword\n",
    "        stop = set(stopwords.words(\"english\"))\n",
    "        #removing stopwords from the raw_review\n",
    "        meaningful_words = [w for w in words if w not in stop]\n",
    "        #return a string with only the words that are important\n",
    "        return(\" \".join(meaningful_words))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_quotes = []\n",
    "\n",
    "for i in range(data.quote.size):\n",
    "    clean_quotes.append(quote_to_words(data.quote[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([    0,     4,     5,     6,     7,     8,     9,    10,    11,\n",
      "               12,\n",
      "            ...\n",
      "            10242, 10243, 10244, 10245, 10246, 10247, 10250, 10251, 10254,\n",
      "            10255],\n",
      "           dtype='int64', length=6337)\n"
     ]
    }
   ],
   "source": [
    "print(index_fresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to fit NB model which outputs the 4 probabilites : Fresh , rotten , word|fresh, word|rotten\n",
    "def NB_fit(X_train,y_train, alpha):\n",
    "\n",
    "    #Probabilities of fresh with alpha values\n",
    "    prob_fresh = (y_train.fresh[y_train.fresh == 'fresh'].count()+ alpha)/(len(y_train)+alpha)\n",
    "    #Probabilities of rotten\n",
    "    prob_rotten = (y_train.fresh[y_train.fresh == 'rotten'].count()+alpha)/(len(y_train)+alpha)\n",
    "    \n",
    "    #Log probabilities of fresh\n",
    "    log_prob_fresh = np.log(prob_fresh)\n",
    "    \n",
    "    #log probabilities of rotten\n",
    "    log_prob_rotten = np.log(prob_rotten)\n",
    "    \n",
    "    index_fresh = y_train[y_train['fresh'] == 'fresh'].index\n",
    "    \n",
    "    index_rotten = y_train[y_train['fresh'] == 'rotten'].index\n",
    "    \n",
    "    X_train_fresh = X_train[index_fresh].sum(axis = 0)\n",
    "    #Probability of word given fresh\n",
    "    prob_w_f = (X_train_fresh+alpha)/(len(y_train[y_train['fresh'] == 'fresh'])+alpha)\n",
    "    \n",
    "    X_train_rotten = X_train[index_rotten].sum(axis = 0)\n",
    "    #Probability of word given rotten\n",
    "    prob_w_r = (X_train_rotten+alpha)/(len(y_train[y_train['fresh'] == 'rotten'])+alpha)\n",
    "    \n",
    "    fresh = pd.DataFrame(pd.Series(words)).reset_index()\n",
    "    fresh.drop(columns = 'index', inplace = True)\n",
    "    fresh['prob_w_f'] = prob_w_f\n",
    "\n",
    "    rotten = pd.DataFrame(pd.Series(words)).reset_index()\n",
    "    rotten.drop(columns = 'index', inplace = True)\n",
    "    rotten['prob_w_r'] = prob_w_r\n",
    "\n",
    "    fresh.rename(columns = {0 : 'words', 'prob_w_f' : 'Pr(W|F)'}, inplace = True)\n",
    "    rotten.rename(columns = {0 : 'words', 'prob_w_r' : 'Pr(W|R)'}, inplace = True)\n",
    "    \n",
    "    fresh['log_Pr_W_F']=fresh['Pr(W|F)'].apply(lambda x: np.log(x))\n",
    "    rotten['log_Pr_W_R']=rotten['Pr(W|R)'].apply(lambda x: np.log(x))\n",
    "    fresh = fresh.replace(to_replace = [np.inf, -np.inf], value = [np.nan, np.nan]).dropna()\n",
    "    rotten = rotten.replace(to_replace = [np.inf, -np.inf], value = [np.nan, np.nan]).dropna()\n",
    "    fresh_T =  fresh.T\n",
    "    fresh_T.columns = fresh_T.iloc[0]\n",
    "    fresh_T.drop(['words', 'Pr(W|F)'], inplace = True)\n",
    "    \n",
    "    rotten_T =  rotten.T\n",
    "    rotten_T.columns = rotten_T.iloc[0]\n",
    "    rotten_T.drop(['words', 'Pr(W|R)'], inplace = True)\n",
    "    \n",
    "    log_word_fresh_list = fresh_T.loc['log_Pr_W_F']\n",
    "    log_word_fresh = pd.DataFrame(columns = test_words_df.columns)\n",
    "    log_word_fresh = log_word_fresh.append(log_word_fresh_list)\n",
    "    \n",
    "    \n",
    "    log_word_rotten_list = rotten_T.loc['log_Pr_W_R']\n",
    "    log_word_rotten = pd.DataFrame(columns = test_words_df.columns)\n",
    "    log_word_rotten = log_word_rotten.append(log_word_rotten_list)\n",
    "    \n",
    "    log_word_rotten.replace(np.nan, 0, inplace = True)\n",
    "    log_word_fresh.replace(np.nan, 0, inplace = True)\n",
    "    \n",
    "    \n",
    "    return log_prob_fresh, log_prob_rotten, log_word_rotten, log_word_fresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Add smoothing to the model. See Schutt p 103 and 109. Smoothing amounts to assuming that we have \u0010seen\u0011 every possible word Œ± > 0 times already, for both classes. (If you wish, you can also assume you have seen the words Œ± times for F and Œ≤ times for R). Note that Œ± does not have to be an integer, and typically the best Œ± < 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding smoothing by passing alpha=0\n",
    "log_prob_fresh, log_prob_rotten, log_word_rotten, log_word_fresh=NB_fit(X_train,y_train, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate accuracy of the fit\n",
    "\n",
    "def predict(X_test, y_test, log_word_fresh, log_word_rotten):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    test_words_df = pd.DataFrame(X_test, columns = words)\n",
    "    test_words_df['log_fresh_pred'] = test_words_df.apply(lambda x : x* log_word_fresh.loc['log_Pr_W_F'] ,axis = 1).sum(axis = 1)\n",
    "    test_words_df['log_rotten_pred'] = (test_words_df.apply(lambda x : x* log_word_rotten.loc['log_Pr_W_R'] ,axis = 1).sum(axis = 1))\n",
    "    test_words_df['y_pred'] = np.where((test_words_df['log_fresh_pred'] > test_words_df['log_rotten_pred']), 'fresh', 'rotten')\n",
    "    \n",
    "    return accuracy_score(y_test['fresh'], test_words_df['y_pred'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7461988304093568"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "predict(X_test, y_test, log_word_fresh, log_word_rotten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_val(k, X, y, alpha):\n",
    "     # Shuffle Indices\n",
    "    #np.random.seed(42)\n",
    "    #shuffled_indices = np.random.permutation(len(X))\n",
    "    #X = X[shuffled_indices]\n",
    "    #y = y[shuffled_indices]\n",
    "    \n",
    "    # Splitting predictors and predictands into k folds\n",
    "    X_split = np.array_split(X, k)\n",
    "    y_split = np.array_split(y, k)\n",
    "    \n",
    "    # Intializing the classification scores\n",
    "    accuracy_sum = 0\n",
    "    \n",
    "    for i in range(k):\n",
    "        X_train = X_split.copy() # Creating a copy of the predictors\n",
    "        X_valid = X_split[i]     # Validation predictors\n",
    "        y_train = y_split.copy() # Copy of the target\n",
    "        y_valid = y_split[i]     # Validation target\n",
    "        del X_train[i]           # Deleting the validation predictors from the training\n",
    "        del y_train[i]           # Deleting the validation target from the training\n",
    "        \n",
    "        # Concatenate the folds into single array\n",
    "        X_train = np.concatenate(X_train)\n",
    "        y_train = np.concatenate(y_train)\n",
    "        \n",
    "        # Performing the model and getting classification scores after each iteration\n",
    "        acc = perform(i, X_train, pd.DataFrame(y_train, columns = ['fresh']).reset_index().drop(columns = ['index']), X_valid, pd.DataFrame(y_valid, columns = ['fresh']).reset_index().drop(columns = ['index']), alpha)\n",
    "        \n",
    "        # Summing the classification scores after each iteration\n",
    "        accuracy_sum = accuracy_sum + acc\n",
    "    \n",
    "    print(\"Average accuracy:\", round((accuracy_sum/k), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform(a, X_train, y_train, X_valid, y_valid, alpha):\n",
    "    from sklearn import metrics # importing the metrics library to calculate classification scores\n",
    "    # Fitting the model with the training data\n",
    "    log_pr_f, log_pr_r, log_pr_w_r, log_pr_w_f = NB_fit(X_train, y_train, alpha)\n",
    "    \n",
    "    # Predicting and Calculating the accuracy\n",
    "    accuracy = predict(X_valid, y_valid, log_pr_w_f, log_pr_w_r)\n",
    "    \n",
    "    print(str(a + 1), \"Accuracy:\", round(accuracy, 2))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Accuracy: 0.73\n",
      "2 Accuracy: 0.72\n",
      "3 Accuracy: 0.74\n",
      "4 Accuracy: 0.71\n",
      "5 Accuracy: 0.74\n",
      "Average accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "kfold_cross_val(5, X_train, np.array(y_train), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roshn\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\roshn\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\roshn\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\roshn\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.7067757 , 0.71929825, 0.70140515])"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using CV with inbuilt lib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_clf = MultinomialNB(alpha = 0.3)\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "cross_val_score(nb_clf, X_test, y_test, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the accuracy with different alpha val\n",
    "\n",
    "alpha = [0.1, 0.3, 0.5]\n",
    "\n",
    "for i in alpha:\n",
    "    print(\"alpha\", i)\n",
    "    kfold_cross_val(3, X_train, np.array(y_train), i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
